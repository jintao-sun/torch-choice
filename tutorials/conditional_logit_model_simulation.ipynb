{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Logit Model on Simulated Dataset\n",
    "**Author: Jintao Sun (jintao.sun@rice.edu)**\n",
    "\n",
    "**Update: May. 8, 2023**\n",
    "\n",
    "**Reference:** This simulation exercise is modified from the [Random Utility Model (RUM) 1: Conditional Logit Model](https://github.com/gsbDBI/torch-choice/blob/main/tutorials/conditional_logit_model_mode_canada.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import essential Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_choice.data import ChoiceDataset, utils\n",
    "from torch_choice.model import ConditionalLogitModel\n",
    "\n",
    "from torch_choice.utils.run_helper import run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run both with and without graphic processing unit (GPU). However, *torch_choice* is *much* faster with GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tutorial on CPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f'CUDA device used: {torch.cuda.get_device_name()}')\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print('Running tutorial on CPU.')\n",
    "    device = 'cpu'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Mac, PyTorch uses the new Metal Performance Shaders (MPS) backend for GPU training acceleration. See [Accelerated PyTorch training on Mac\n",
    "](https://developer.apple.com/metal/pytorch/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if torch.backends.mps.is_available():\n",
    "#    print(f'MPS device used.')\n",
    "#    device = 'mps'\n",
    "#else:\n",
    "#    print('Running tutorial on CPU.')\n",
    "#    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "We have included the `ModeCanada` dataset in our package, which is located at `./public_datasets/`.\n",
    "\n",
    "The `ModeCanada` dataset contains individuals' choice on traveling methods.\n",
    "\n",
    "The raw dataset is in a long-format, in which the `case` variable identifies each choice.\n",
    "Using the terminology mentioned in the data management tutorial, each choice is called a *purchasing record* (i.e., consumer bought the ticket of a particular travelling mode), and the total number of choices made is denoted as $B$.\n",
    "\n",
    "For example, the first four row below (with `case == 109`) corresponds to the first choice, the `alt` column lists all alternatives/items available.\n",
    "\n",
    "The `choice` column identifies which alternative/item is chosen. The second row in the data snapshot below, we have `choice == 1` and `alt == 'air'` for `case == 109`. This indicates the travelling mode chosen in `case = 109` was `air`.\n",
    "\n",
    "Now we convert the raw dataset into the format compatible with our model, for a detailed tutorial on the compatible formats, please refer to the data management tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We focus on cases when four alternatives were available by filtering `noalt == 4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>case</th>\n",
       "      <th>alt</th>\n",
       "      <th>choice</th>\n",
       "      <th>dist</th>\n",
       "      <th>cost</th>\n",
       "      <th>ivt</th>\n",
       "      <th>ovt</th>\n",
       "      <th>freq</th>\n",
       "      <th>income</th>\n",
       "      <th>urban</th>\n",
       "      <th>noalt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>304</td>\n",
       "      <td>109</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>377</td>\n",
       "      <td>58.25</td>\n",
       "      <td>215</td>\n",
       "      <td>74</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>305</td>\n",
       "      <td>109</td>\n",
       "      <td>air</td>\n",
       "      <td>1</td>\n",
       "      <td>377</td>\n",
       "      <td>142.80</td>\n",
       "      <td>56</td>\n",
       "      <td>85</td>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>306</td>\n",
       "      <td>109</td>\n",
       "      <td>bus</td>\n",
       "      <td>0</td>\n",
       "      <td>377</td>\n",
       "      <td>27.52</td>\n",
       "      <td>301</td>\n",
       "      <td>63</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>307</td>\n",
       "      <td>109</td>\n",
       "      <td>car</td>\n",
       "      <td>0</td>\n",
       "      <td>377</td>\n",
       "      <td>71.63</td>\n",
       "      <td>262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>308</td>\n",
       "      <td>110</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>377</td>\n",
       "      <td>58.25</td>\n",
       "      <td>215</td>\n",
       "      <td>74</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  case    alt  choice  dist    cost  ivt  ovt  freq  income  \\\n",
       "0         304   109  train       0   377   58.25  215   74     4      45   \n",
       "1         305   109    air       1   377  142.80   56   85     9      45   \n",
       "2         306   109    bus       0   377   27.52  301   63     8      45   \n",
       "3         307   109    car       0   377   71.63  262    0     0      45   \n",
       "4         308   110  train       0   377   58.25  215   74     4      70   \n",
       "\n",
       "   urban  noalt  \n",
       "0      0      4  \n",
       "1      0      4  \n",
       "2      0      4  \n",
       "3      0      4  \n",
       "4      0      4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./public_datasets/ModeCanada.csv')\n",
    "df = df.query('noalt == 4').reset_index(drop=True)\n",
    "df.sort_values(by='case', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are 4 rows corresponding to each *purchasing record*, the length of the long-format data is $4 \\times B$.\n",
    "Please refer to the data management tutorial for notations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11116, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the `item_index` tensor\n",
    "The first thing is to construct the `item_index` tensor identifying which item (i.e., travel mode) was chosen in each purchasing record.\n",
    "\n",
    "We can now construct the `item_index` array containing which item was chosen in each purchasing record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       air\n",
      "1       air\n",
      "2       air\n",
      "3       air\n",
      "4       air\n",
      "       ... \n",
      "2774    car\n",
      "2775    car\n",
      "2776    car\n",
      "2777    car\n",
      "2778    car\n",
      "Name: alt, Length: 2779, dtype: object\n"
     ]
    }
   ],
   "source": [
    "item_index = df[df['choice'] == 1].sort_values(by='case')['alt'].reset_index(drop=True)\n",
    "print(item_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will be training our model using `PyTorch`, we need to encode `{'air', 'bus', 'car', 'train'}` into integer values.\n",
    "\n",
    "| Travel Mode Name      | Encoded Integer Values |\n",
    "| :---     | :----:  |\n",
    "| air      | 0       |\n",
    "| bus      | 1       |\n",
    "| car      | 2       |\n",
    "| train    | 3       |\n",
    "\n",
    "The generated `item_index` would be a tensor of shape 2,778 (i.e., number of purchasing records in this dataset) with values `{0, 1, 2, 3}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder={'air': 0, 'bus': 1, 'car': 2, 'train': 3}\n",
      "item_index=tensor([0, 0, 0,  ..., 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "item_names = ['air', 'bus', 'car', 'train']\n",
    "num_items = 4\n",
    "encoder = dict(zip(item_names, range(num_items)))\n",
    "print(f\"{encoder=:}\")\n",
    "item_index = item_index.map(lambda x: encoder[x])\n",
    "item_index = torch.LongTensor(item_index)\n",
    "print(f\"{item_index=:}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Observables\n",
    "\n",
    "Then let's constrct tensors for observables.\n",
    "As mentioned in the data management tutorial, the *session* is capturing the temporal dimension of our data.\n",
    "Since we have different values `cost`, `freq` and `ovt` for each purchasing record and for each item, it's natural to say each purchasing record has its own session.\n",
    "\n",
    "Consequently, these three variables are `price` observables since they vary by both item and session.\n",
    "The tensor holding these observables has shape $(\\text{numer of purchasing records}, \\text{number of items}, 3)$\n",
    "\n",
    "We do the same for variable `ivt`, we put `ivt` into a separate tensor because we want to model its coefficient differently later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price_cost_freq_ovt.shape=torch.Size([2779, 4, 3])\n",
      "price_ivt.shape=torch.Size([2779, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "price_cost_freq_ovt = utils.pivot3d(df, dim0='case', dim1='alt',\n",
    "                                    values=['cost', 'freq', 'ovt'])\n",
    "print(f'{price_cost_freq_ovt.shape=:}')\n",
    "\n",
    "price_ivt = utils.pivot3d(df, dim0='case', dim1='alt', values='ivt')\n",
    "print(f'{price_ivt.shape=:}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[142.8000,   9.0000,  85.0000],\n",
       "         [ 27.5200,   8.0000,  63.0000],\n",
       "         [ 71.6300,   0.0000,   0.0000],\n",
       "         [ 58.2500,   4.0000,  74.0000]],\n",
       "\n",
       "        [[142.8000,   9.0000,  85.0000],\n",
       "         [ 27.5200,   8.0000,  63.0000],\n",
       "         [ 71.6300,   0.0000,   0.0000],\n",
       "         [ 58.2500,   4.0000,  74.0000]],\n",
       "\n",
       "        [[142.8000,   9.0000,  85.0000],\n",
       "         [ 27.5200,   8.0000,  63.0000],\n",
       "         [ 71.6300,   0.0000,   0.0000],\n",
       "         [ 58.2500,   4.0000,  74.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[155.3000,  16.0000, 135.0000],\n",
       "         [ 27.9600,  24.0000, 130.0000],\n",
       "         [ 64.9800,   0.0000,   0.0000],\n",
       "         [ 58.1000,   3.0000, 135.0000]],\n",
       "\n",
       "        [[155.3000,  16.0000, 135.0000],\n",
       "         [ 27.9600,  24.0000, 130.0000],\n",
       "         [ 64.9800,   0.0000,   0.0000],\n",
       "         [ 58.1000,   3.0000, 135.0000]],\n",
       "\n",
       "        [[155.3000,  16.0000, 115.0000],\n",
       "         [ 27.9600,  24.0000, 140.0000],\n",
       "         [ 73.7200,   0.0000,   0.0000],\n",
       "         [ 58.6000,   3.0000, 145.0000]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_cost_freq_ovt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.],\n",
       "         [301.],\n",
       "         [262.],\n",
       "         [215.]],\n",
       "\n",
       "        [[ 56.],\n",
       "         [301.],\n",
       "         [262.],\n",
       "         [215.]],\n",
       "\n",
       "        [[ 56.],\n",
       "         [301.],\n",
       "         [262.],\n",
       "         [215.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 46.],\n",
       "         [186.],\n",
       "         [245.],\n",
       "         [193.]],\n",
       "\n",
       "        [[ 46.],\n",
       "         [186.],\n",
       "         [245.],\n",
       "         [193.]],\n",
       "\n",
       "        [[ 46.],\n",
       "         [186.],\n",
       "         [297.],\n",
       "         [193.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_ivt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast, the `income` variable varies only by session (i.e., purchasing record), but not by item. `income` is therefore naturally a `session` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session_income.shape=torch.Size([2779, 1])\n"
     ]
    }
   ],
   "source": [
    "session_income = df.groupby('case')['income'].first()\n",
    "session_income = torch.Tensor(session_income.values).view(-1, 1)\n",
    "print(f'{session_income.shape=:}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, the `ChoiceDataset` constructed contains 2779 choice records. Since the original dataset did not reveal the identity of each decision maker, we consider all 2779 choices were made by a single user but in 2779 different sessions to handle variations.\n",
    "\n",
    "In this case, the `cost`, `freq` and `ovt` are observables depending on both sessions and items, we created a `price_cost_freq_ovt` tensor with shape `(num_sessions, num_items, 3) = (2779, 4, 3)` to contain these variables.\n",
    "In contrast, the `income` information depends only on session but not on items, hence we create the `session_income` tensor to store it.\n",
    "\n",
    "Because we wish to fit item-specific coefficients for the `ivt` variable, which varies by both sessions and items as well, we create another `price_ivt` tensor in addition to the `price_cost_freq_ovt` tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we put all tensors we created to a single `ChoiceDataset` object, and move the dataset to the appropriate device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No `session_index` is provided, assume each choice instance is in its own session.\n"
     ]
    }
   ],
   "source": [
    "dataset = ChoiceDataset(item_index=item_index,\n",
    "                        price_cost_freq_ovt=price_cost_freq_ovt,\n",
    "                        session_income=session_income,\n",
    "                        price_ivt=price_ivt\n",
    "                        ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can `print(dataset)` to check shapes of tensors contained in the `ChoiceDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChoiceDataset(label=[], item_index=[2779], user_index=[], session_index=[2779], item_availability=[], price_cost_freq_ovt=[2779, 4, 3], session_income=[2779, 1], price_ivt=[2779, 4, 1], device=cpu)\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChoiceDataset(label=[], item_index=[2779], user_index=[], session_index=[2779], item_availability=[], price_cost_freq_ovt=[2779, 4, 3], session_income=[2779, 1], price_ivt=[2779, 4, 1], device=cpu)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Model\n",
    "We now construct the `ConditionalLogitModel` to fit the dataset we constructed above.\n",
    "\n",
    "To start with, we aim to estimate the following model formulation:\n",
    "\n",
    "$$\n",
    "U_{uit} = \\beta^0_i + \\beta^{1\\top} X^{price: (cost, freq, ovt)}_{it} + \\beta^2_i X^{session:income}_t + \\beta^3_i X_{it}^{price:ivt} + \\epsilon_{uit}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now initialize the `ConditionalLogitModel` to predict choices from the dataset.\n",
    "Please see the documentation for a complete description of the `ConditionalLogitModel` class.\n",
    "\n",
    "At it's core, the `ConditionalLogitModel` constructor requires the following four components.\n",
    "\n",
    "### Define variation of each $\\beta$ using `coef_variation_dict`\n",
    "The keyword `coef_variation_dict` is a dictionary with variable names (defined above while constructing the dataset) as keys and values from `{constant, user, item, item-full}`.\n",
    "\n",
    "For instance, since we wish to have constant coefficients for `cost`, `freq` and `ovt` observables, and these three observables are stored in the `price_cost_freq_ovt` tensor of the choice dataset, we set `coef_variation_dict['price_cost_freq_ovt'] = 'constant'` (corresponding to the $\\beta^{1\\top} X^{price: (cost, freq, ovt)}_{it}$ term above).\n",
    "\n",
    "The models allows for the option of zeroing coefficient for one item.\n",
    "The variation of $\\beta^3$ above is specified as `item-full` which indicates 4 values of $\\beta^3$ is learned (one for each item).\n",
    "In contrast, $\\beta^0, \\beta^2$ are specified to have variation `item` instead of `item-full`. In this case, the $\\beta$ correspond to the first item (i.e., the baseline item, which is encoded as 0 in the label tensor, `air` in our example) is force to be zero.\n",
    "\n",
    "The researcher needs to declare `intercept` explicitly for the model to fit an intercept as well, otherwise the model assumes zero intercept term.\n",
    "\n",
    "### Define the dimension of each $\\beta$ using `num_param_dict`\n",
    "The `num_param_dict` is a dictionary with keys exactly the same as the `coef_variation_dict`.\n",
    "Each of dictionary values tells the dimension of the corresponding observables, hence the dimension of the coefficient.\n",
    "For example, the `price_cost_freq_ovt` consists of three observables and we set the corresponding to three.\n",
    "\n",
    "Even the model can infer `num_param_dict['intercept'] = 1`, but we recommend the research to include it for completeness.\n",
    "   \n",
    "### Number of items\n",
    "The `num_items` keyword informs the model how many alternatives users are choosing from.\n",
    "\n",
    "### Number of users\n",
    "The `num_users` keyword is an optional integer informing the model how many users there are in the dataset. However, in this example we implicitly assume there is only one user making all the decisions and we do not have any `user_obs` involved, hence `num_users` argument is not supplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConditionalLogitModel(coef_variation_dict={'price_cost_freq_ovt': 'constant',\n",
    "                                                   'session_income': 'item',\n",
    "                                                   'price_ivt': 'item-full',\n",
    "                                                   'intercept': 'item'},\n",
    "                              num_param_dict={'price_cost_freq_ovt': 3,\n",
    "                                              'session_income': 1,\n",
    "                                              'price_ivt': 1,\n",
    "                                              'intercept': 1},\n",
    "                              num_items=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we move the model to the appropriate device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can print the `ConditionalLogitModel` object to obtain a summary of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConditionalLogitModel(\n",
      "  (coef_dict): ModuleDict(\n",
      "    (price_cost_freq_ovt[constant]): Coefficient(variation=constant, num_items=4, num_users=None, num_params=3, 3 trainable parameters in total, device=cpu).\n",
      "    (session_income[item]): Coefficient(variation=item, num_items=4, num_users=None, num_params=1, 3 trainable parameters in total, device=cpu).\n",
      "    (price_ivt[item-full]): Coefficient(variation=item-full, num_items=4, num_users=None, num_params=1, 4 trainable parameters in total, device=cpu).\n",
      "    (intercept[item]): Coefficient(variation=item, num_items=4, num_users=None, num_params=1, 3 trainable parameters in total, device=cpu).\n",
      "  )\n",
      ")\n",
      "Conditional logistic discrete choice model, expects input features:\n",
      "\n",
      "X[price_cost_freq_ovt[constant]] with 3 parameters, with constant level variation.\n",
      "X[session_income[item]] with 1 parameters, with item level variation.\n",
      "X[price_ivt[item-full]] with 1 parameters, with item-full level variation.\n",
      "X[intercept[item]] with 1 parameters, with item level variation.\n",
      "device=cpu\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model using Formula\n",
    "Alternatively, researchers can create the model using a `formula` like in R.\n",
    "\n",
    "The formula consists of a list of additive terms separated by `+` sign, and each term looks like `(variable_name|variation)`. Where `variable_name` is the name of the variable in the dataset, and `variation` is one of `constant`, `user`, `item`, `item-full`. Initializing the model using `formula` requires you to pass in the `ChoiceDataset` object as well so that the model can infer the dimension of each variable.\n",
    "\n",
    "These two ways of creating models lead to equivalent models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model = ConditionalLogitModel(\n",
    "    formula='(price_cost_freq_ovt|constant) + (session_income|item) + (price_ivt|item-full) + (intercept|item)',\n",
    "    dataset=dataset,\n",
    "    num_items=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConditionalLogitModel(\n",
      "  (coef_dict): ModuleDict(\n",
      "    (price_cost_freq_ovt[constant]): Coefficient(variation=constant, num_items=4, num_users=None, num_params=3, 3 trainable parameters in total, device=cpu).\n",
      "    (session_income[item]): Coefficient(variation=item, num_items=4, num_users=None, num_params=1, 3 trainable parameters in total, device=cpu).\n",
      "    (price_ivt[item-full]): Coefficient(variation=item-full, num_items=4, num_users=None, num_params=1, 4 trainable parameters in total, device=cpu).\n",
      "    (intercept[item]): Coefficient(variation=item, num_items=4, num_users=None, num_params=1, 3 trainable parameters in total, device=cpu).\n",
      "  )\n",
      ")\n",
      "Conditional logistic discrete choice model, expects input features:\n",
      "\n",
      "X[price_cost_freq_ovt[constant]] with 3 parameters, with constant level variation.\n",
      "X[session_income[item]] with 1 parameters, with item level variation.\n",
      "X[price_ivt[item-full]] with 1 parameters, with item-full level variation.\n",
      "X[intercept[item]] with 1 parameters, with item level variation.\n",
      "device=cpu\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "We provide an easy-to-use helper function `run()` imported from `torch_choice.utils.run_helper` to fit the model with a particular dataset.\n",
    "\n",
    "We provide an easy-to-use model runner for both `ConditionalLogitModel` and `NestedLogitModel` (see later) instances.\n",
    "\n",
    "The `run()` mehtod supports mini-batch updating as well, for small datasets like the one we are dealing right now, we can use `batch_size = -1` to conduct full-batch gradient update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== received model ====================\n",
      "ConditionalLogitModel(\n",
      "  (coef_dict): ModuleDict(\n",
      "    (price_cost_freq_ovt[constant]): Coefficient(variation=constant, num_items=4, num_users=None, num_params=3, 3 trainable parameters in total, device=cpu).\n",
      "    (session_income[item]): Coefficient(variation=item, num_items=4, num_users=None, num_params=1, 3 trainable parameters in total, device=cpu).\n",
      "    (price_ivt[item-full]): Coefficient(variation=item-full, num_items=4, num_users=None, num_params=1, 4 trainable parameters in total, device=cpu).\n",
      "    (intercept[item]): Coefficient(variation=item, num_items=4, num_users=None, num_params=1, 3 trainable parameters in total, device=cpu).\n",
      "  )\n",
      ")\n",
      "Conditional logistic discrete choice model, expects input features:\n",
      "\n",
      "X[price_cost_freq_ovt[constant]] with 3 parameters, with constant level variation.\n",
      "X[session_income[item]] with 1 parameters, with item level variation.\n",
      "X[price_ivt[item-full]] with 1 parameters, with item-full level variation.\n",
      "X[intercept[item]] with 1 parameters, with item level variation.\n",
      "device=cpu\n",
      "==================== received dataset ====================\n",
      "ChoiceDataset(label=[], item_index=[2779], user_index=[], session_index=[2779], item_availability=[], price_cost_freq_ovt=[2779, 4, 3], session_income=[2779, 1], price_ivt=[2779, 4, 1], device=cpu)\n",
      "==================== training the model ====================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m start_time \u001b[39m=\u001b[39m time()\n\u001b[0;32m----> 2\u001b[0m run(model, dataset, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m50000\u001b[39;49m, learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTime taken:\u001b[39m\u001b[39m'\u001b[39m, time() \u001b[39m-\u001b[39m start_time)\n",
      "File \u001b[0;32m~/Library/CloudStorage/Dropbox/GitHub_repos/torch-choice/torch_choice/utils/run_helper.py:40\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(model, dataset, dataset_test, batch_size, learning_rate, num_epochs, report_frequency, compute_std, return_final_training_log_likelihood)\u001b[0m\n\u001b[1;32m     38\u001b[0m item_index \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mitem\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mitem_index \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, NestedLogitModel) \u001b[39melse\u001b[39;00m batch\u001b[39m.\u001b[39mitem_index\n\u001b[1;32m     39\u001b[0m \u001b[39m# the model.loss returns negative log-likelihood + regularization term.\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mloss(batch, item_index)\n\u001b[1;32m     42\u001b[0m \u001b[39mif\u001b[39;00m (e \u001b[39m%\u001b[39m report_frequency) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     43\u001b[0m     \u001b[39m# record log-likelihood.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     ll \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mnegative_log_likelihood(batch, item_index)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mitem() \u001b[39m# * len(batch)\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/Dropbox/GitHub_repos/torch-choice/torch_choice/model/conditional_logit_model.py:285\u001b[0m, in \u001b[0;36mConditionalLogitModel.loss\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    284\u001b[0m     \u001b[39m\"\"\"The loss function to be optimized. This is a wrapper of `negative_log_likelihood` + regularization loss if required.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     nll \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnegative_log_likelihood(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    286\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregularization \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m         L \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mL1\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mL2\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m2\u001b[39m}[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregularization]\n",
      "File \u001b[0;32m~/Library/CloudStorage/Dropbox/GitHub_repos/torch-choice/torch_choice/model/conditional_logit_model.py:274\u001b[0m, in \u001b[0;36mConditionalLogitModel.negative_log_likelihood\u001b[0;34m(self, batch, y, is_train)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39m\"\"\"Computes the log-likelihood for the batch and label.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[39mTODO: consider remove y, change to label.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[39mTODO: consider move this method outside the model, the role of the model is to compute the utility.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[39m    torch.Tensor: the negative log-likelihood.\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[39mif\u001b[39;00m is_train:\n\u001b[0;32m--> 274\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m    275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    276\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:2288\u001b[0m, in \u001b[0;36mModule.train\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   2286\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m mode\n\u001b[1;32m   2287\u001b[0m \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m-> 2288\u001b[0m     module\u001b[39m.\u001b[39;49mtrain(mode)\n\u001b[1;32m   2289\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:2286\u001b[0m, in \u001b[0;36mModule.train\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   2284\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(mode, \u001b[39mbool\u001b[39m):\n\u001b[1;32m   2285\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mtraining mode is expected to be boolean\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2286\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m mode\n\u001b[1;32m   2287\u001b[0m \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m   2288\u001b[0m     module\u001b[39m.\u001b[39mtrain(mode)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1674\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1672\u001b[0m     buffers[name] \u001b[39m=\u001b[39m value\n\u001b[1;32m   1673\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1674\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__setattr__\u001b[39;49m(name, value)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "run(model, dataset, num_epochs=50000, learning_rate=0.01, batch_size=-1)\n",
    "print('Time taken:', time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Estimation from `R`\n",
    "The following is the R-output from the `mlogit` implementation, the estimation, standard error, and log-likelihood from our `torch_choice` implementation is the same as the result from `mlogit` implementation.\n",
    "\n",
    "We see that the final log-likelihood of models estimated using two packages are all around `-1874`.\n",
    "\n",
    "The `run()` method calculates the standard deviation using $\\sqrt{\\text{diag}(H^{-1})}$, where $H$ is the hessian of negative log-likelihood with repsect to model parameters.\n",
    "\n",
    "Names of coefficients are slightly different, one can use the following conversion table to compare estimations and standard deviations reported by both packages.\n",
    "\n",
    "<!-- | Coefficient Name in Python |  Estimation |   Std. Err. |  Coeffcient Name in R | R Estimation | R Std. Err. | \n",
    "|:---------------------:|-------------:|------------:| :--------------: | ----------: | ------: |\n",
    "| price_cost_freq_ovt_0 |  -0.0342194  |  0.00731707 | cost             | -0.0333389  |0.0070955|\n",
    "| price_cost_freq_ovt_1 |   0.092262   |  0.00520946 | freq             |  0.0925297  |0.0050976|\n",
    "| price_cost_freq_ovt_2 |  -0.0439827  |  0.00342765 | ovt              | -0.0430036  |0.0032247|\n",
    "| session_income_0      |  -0.0901207  |  0.0205214  | income:bus       | -0.0890867  |0.0183471|\n",
    "| session_income_1      |  -0.0272581  |  0.00385396 | income:car       | -0.0279930  |0.0038726|\n",
    "| session_income_2      |  -0.0390468  |  0.00428838 | ivt:train        | -0.0014504  |0.0011875|\n",
    "| price_ivt_0           |   0.0592097  |  0.0102933  | ivt:air          |  0.0595097  |0.0100727|\n",
    "| price_ivt_1           |  -0.00753696 |  0.00496264 | ivt:bus          | -0.0067835  |0.0044334|\n",
    "| price_ivt_2           |  -0.00604297 |  0.00193414 | ivt:car          | -0.0064603  |0.0018985|\n",
    "| price_ivt_3           |  -0.00207518 |  0.00123286 | ivt:train        | -0.0014504  |0.0011875|\n",
    "| intercept_0           |   0.700786   |  1.39368    | (Intercept):bus  |  0.6983381  |1.2802466|\n",
    "| intercept_1           |   1.85016    |  0.728283   | (Intercept):car  |  1.8441129  |0.7085089|\n",
    "| intercept_2           |   3.2782     |  0.648064   | (Intercept):train|  3.2741952  |0.6244152| -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R Output\n",
    "```r\n",
    "install.packages(\"mlogit\")\n",
    "library(\"mlogit\")\n",
    "data(\"ModeCanada\", package = \"mlogit\")\n",
    "MC <- dfidx(ModeCanada, subset = noalt == 4)\n",
    "ml.MC1 <- mlogit(choice ~ cost + freq + ovt | income | ivt, MC, reflevel='air')\n",
    "\n",
    "summary(ml.MC1)\n",
    "```\n",
    "```\n",
    "Call:\n",
    "mlogit(formula = choice ~ cost + freq + ovt | income | ivt, data = MC, \n",
    "    reflevel = \"air\", method = \"nr\")\n",
    "\n",
    "Frequencies of alternatives:choice\n",
    "      air     train       bus       car \n",
    "0.3738755 0.1666067 0.0035984 0.4559194 \n",
    "\n",
    "nr method\n",
    "9 iterations, 0h:0m:0s \n",
    "g'(-H)^-1g = 0.00014 \n",
    "successive function values within tolerance limits \n",
    "\n",
    "Coefficients :\n",
    "                    Estimate Std. Error  z-value  Pr(>|z|)    \n",
    "(Intercept):train  3.2741952  0.6244152   5.2436 1.575e-07 ***\n",
    "(Intercept):bus    0.6983381  1.2802466   0.5455 0.5854292    \n",
    "(Intercept):car    1.8441129  0.7085089   2.6028 0.0092464 ** \n",
    "cost              -0.0333389  0.0070955  -4.6986 2.620e-06 ***\n",
    "freq               0.0925297  0.0050976  18.1517 < 2.2e-16 ***\n",
    "ovt               -0.0430036  0.0032247 -13.3356 < 2.2e-16 ***\n",
    "income:train      -0.0381466  0.0040831  -9.3426 < 2.2e-16 ***\n",
    "income:bus        -0.0890867  0.0183471  -4.8556 1.200e-06 ***\n",
    "income:car        -0.0279930  0.0038726  -7.2286 4.881e-13 ***\n",
    "ivt:air            0.0595097  0.0100727   5.9080 3.463e-09 ***\n",
    "ivt:train         -0.0014504  0.0011875  -1.2214 0.2219430    \n",
    "ivt:bus           -0.0067835  0.0044334  -1.5301 0.1259938    \n",
    "ivt:car           -0.0064603  0.0018985  -3.4029 0.0006668 ***\n",
    "---\n",
    "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
    "\n",
    "Log-Likelihood: -1874.3\n",
    "McFadden R^2:  0.35443 \n",
    "Likelihood ratio test : chisq = 2058.1 (p.value = < 2.22e-16)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "5859d33511df864b0b7226a715510a0165ef032ed4b83eb4ae2c092f0788759c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
